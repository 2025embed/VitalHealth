/* AUTOGENERATED DO NOT MODIFY */

/**
  ******************************************************************************
  * @file    tof.c
  * @brief   NN Code autogenerated DO NOT MODIFY IT
  ******************************************************************************
  * @attention
  *
  * Copyright (c) 2023 STMicroelectronics.
  * All rights reserved.
  *
  * This software is licensed under terms that can be found in the LICENSE file
  * in the root directory of this software component.
  * If no LICENSE file comes with this software, it is provided AS-IS.
  *
  ******************************************************************************
  */

/*
 * GIT_SHA         "0307e413493a9893cb1f0a1266b856e2af3bba2b"
 * GIT_BRANCH      "STAI-2.0"
 * GIT_DESCRIPTION "STAI-2.0-RC1-1-1-g0307e413"
 *
 * Command Line options:
 * --onnx-input = "C:/Users/Zhangyifan/.stm32cubemx/network_output/tof_model_OE_3_1_0.onnx"
 * --out-dir-prefix = "C:/Users/Zhangyifan/AppData/Local/Temp/mxAI_workspace6022188527164003590162142310721150/neural_art__tof/"
 * --network-name = "tof"
 * --all-buffers-info = true
 * --mvei = true
 * --load-mdesc-file = "D:/STM32cubemx/Respository/Packs/STMicroelectronics/X-CUBE-AI/10.0.0/Utilities/configs/stm32n6"
 * --load-mpool-file = "D:/STM32cubemx/Respository/Packs/STMicroelectronics/X-CUBE-AI/10.0.0/scripts/N6_scripts/my_mpools/TOF"
 * --cache-maintenance = true
 * --enable-virtual-mem-pools = true
 * --native-float = true
 * --json-quant-file = "C:/Users/Zhangyifan/.stm32cubemx/network_output/tof_model_OE_3_1_0_Q.json"
 * --optimization = 3
 * --Os = true
 * --Omax-ca-pipe = 4
 * --Ocache-opt = true
 * --output-info-file = "c_info"
 * --Oalt-sched = true
 * --no-hw-sw-parallelism = true
 * --Oshuffle-dma = true
 */

#include "ll_aton_NN_interface.h"
#include "ll_aton.h"
#include "ll_aton_lib.h"
#include "ll_aton_version.h"
#include "ll_sw.h"

#if LL_ATON_VERSION_MAJOR != 1 || LL_ATON_VERSION_MINOR != 0 || LL_ATON_VERSION_MICRO != 0 || LL_ATON_VERSION_DEV != 16
#  warning "Possible mismatch in ll_aton library used"
#endif

#if !defined(LL_ATON_DBG_BUFFER_INFO_EXCLUDED)
#  define LL_ATON_DBG_BUFFER_INFO_EXCLUDED 0
#endif

/* global pool 7 is ? */
/* index=7 file postfix=xSPI1 name=hyperRAM offset=0x90000000  absolute_mode size=33554424 READ_WRITE THROUGHPUT=MID LATENCY=HIGH byte width=2 freq ratio=5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=ON read_power=380 write_power=340 use4initializers=YES score=82  */
/* global pool 8 is 85.77 KB */
/* index=8 file postfix=xSPI2 name=octoFlash offset=0x70500000  absolute_mode size=1048568 READ_ONLY THROUGHPUT=MID LATENCY=HIGH byte width=1 freq ratio=6 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=ON read_power=110 write_power=400 use4initializers=YES score=50  */
/* global pool 1 is 8.25 KB */
/* index=1 file postfix=AXISRAM5 name=npuRAM5 offset=0x342e0000  absolute_mode size=458752 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=18.531 write_power=16.201 use4initializers=NO score=94  */
/* global pool 2 is ? */
/* index=2 file postfix=AXISRAM4 name=npuRAM4 offset=0x34270000  absolute_mode size=458752 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=18.531 write_power=16.201 use4initializers=NO score=94  */
/* global pool 3 is ? */
/* index=3 file postfix=AXISRAM3 name=npuRAM3 offset=0x34200000  absolute_mode size=458752 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=18.531 write_power=16.201 use4initializers=NO score=94  */
/* global pool 0 is ? */
/* index=0 file postfix=AXISRAM6 name=npuRAM6 offset=0x34350000  absolute_mode size=458744 READ_WRITE THROUGHPUT=HIGH LATENCY=LOW byte width=8 freq ratio=1.25 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=19.006 write_power=15.79 use4initializers=NO score=94  */
/* global pool 10 is 1.88 MB */
/* index=10 file postfix=AXISRAM2_AXISRAM3_AXISRAM4_AXISRAM5_AXISRAM6 name=cpuRAM2_npuRAM3_npuRAM4_npuRAM5_npuRAM6 offset=0x34100000  absolute_mode size=2883576 vpool READ_WRITE THROUGHPUT=MID LATENCY=MID byte width=8 freq ratio=2.5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=19.006 write_power=16.201 use4initializers=NO score=85  */
/* global pool 4 is ? */
/* index=4 file postfix=AXISRAM2 name=cpuRAM2 offset=0x34100000  absolute_mode size=1048576 READ_WRITE THROUGHPUT=MID LATENCY=MID byte width=8 freq ratio=2.5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=17.324 write_power=15.321 use4initializers=NO score=84  */
/* global pool 5 is ? */
/* index=5 file postfix=AXISRAM1 name=cpuRAM1 offset=0x34064000  absolute_mode size=0 READ_WRITE THROUGHPUT=MID LATENCY=MID byte width=8 freq ratio=2.5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=16.616 write_power=14.522 use4initializers=NO score=84  */
/* global pool 6 is ? */
/* index=6 file postfix=AXIFLEXMEM name=flexMEM offset=0x34000000  absolute_mode size=0 READ_WRITE THROUGHPUT=MID LATENCY=MID byte width=8 freq ratio=2.5 burst max length=MAXINT burst penalty=0 pipelined=ON cacheable=OFF read_power=9.381 write_power=8.569 use4initializers=NO score=84  */

LL_ATON_User_IO_Result_t LL_ATON_Set_User_Input_Buffer_tof(uint32_t num, void* buffer, uint32_t size)
{
  { 
    return LL_ATON_User_IO_WRONG_INDEX;
  }
}

void *LL_ATON_Get_User_Input_Buffer_tof(uint32_t num)
{
  { 
    return NULL;
  }
}

LL_ATON_User_IO_Result_t LL_ATON_Set_User_Output_Buffer_tof(uint32_t num, void* buffer, uint32_t size)
{
  { 
    return LL_ATON_User_IO_WRONG_INDEX;
  }
}

void *LL_ATON_Get_User_Output_Buffer_tof(uint32_t num)
{
  { 
    return NULL;
  }
}

bool LL_ATON_EC_Network_Init_tof(void)
{
  return true;
}

bool LL_ATON_EC_Inference_Init_tof(void)
{
  return true;
}

/* scheduling epoch=0    nodes=9   ------------------------------------------------------------------- */

/* scheduling epoch=1    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_1(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Conv node=Conv2D_1 */
  Conv_sw_info conv1_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 8,
    .general.input.dim.tensor_w = 8,
    .general.input.dim.tensor_c = 1,
    .general.input.dim.num_elem = 64,
    .general.input.stride.b = 256,
    .general.input.stride.h = 32,
    .general.input.stride.w = 4,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "weights" tensor-related info: */
    .weights.dim.tensor_b = 16,
    .weights.dim.tensor_h = 3,
    .weights.dim.tensor_w = 3,
    .weights.dim.tensor_c = 1,
    .weights.dim.num_elem = 144,
    .weights.stride.b = 36,
    .weights.stride.h = 12,
    .weights.stride.w = 4,
    .weights.stride.c = 4,
    .weights.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x70500000UL + 86528) /* Equivalent hex address = 0x70515200UL */,
    .weights.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 8,
    .general.output.dim.tensor_w = 8,
    .general.output.dim.tensor_c = 16,
    .general.output.dim.num_elem = 1024,
    .general.output.stride.b = 4096,
    .general.output.stride.h = 512,
    .general.output.stride.w = 64,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) /* Equivalent hex address = 0x342e0100UL */,
    .general.output.format.is_signed = 0,
    /* Node-specific Hyper-parameters: */
    .ngroup = 1,
    .pads = {1, 1, 1, 1},
    .strides = {1, 1},
    .dilations = {1, 1},
    .general.type = LL_SW_CONV,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Conv2D_1 mapped on EmbedNets (FLOAT) as Conv | Category: Computational */
  ll_sw_forward_conv(&conv1_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 4352) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) /* Equivalent hex address = 0x342e0100UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 4352) /* Equivalent hex address = 0x342e1100UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=2    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_2(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Add node=Conv2D_1_addbias12 */
  Arith_sw_info arith2_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 8,
    .general.input.dim.tensor_w = 8,
    .general.input.dim.tensor_c = 16,
    .general.input.dim.num_elem = 1024,
    .general.input.stride.b = 4096,
    .general.input.stride.h = 512,
    .general.input.stride.w = 64,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 256) /* Equivalent hex address = 0x342e0100UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 16,
    .operand.dim.num_elem = 16,
    .operand.stride.b = 64,
    .operand.stride.h = 64,
    .operand.stride.w = 64,
    .operand.stride.c = 4,
    .operand.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x70500000UL + 87744) /* Equivalent hex address = 0x705156c0UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 8,
    .general.output.dim.tensor_w = 8,
    .general.output.dim.tensor_c = 16,
    .general.output.dim.num_elem = 1024,
    .general.output.stride.b = 4096,
    .general.output.stride.h = 512,
    .general.output.stride.w = 64,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 4352) /* Equivalent hex address = 0x342e1100UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_ARITHADD,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Conv2D_1_addbias12 mapped on EmbedNets (FLOAT) as Add | Category: Computational */
  ll_sw_forward_arith(&arith2_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 4352) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 8448) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 4352) /* Equivalent hex address = 0x342e1100UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 8448) /* Equivalent hex address = 0x342e2100UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=3    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_3(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Relu node=Relu_2 */
  Activ_sw_info activ3_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 8,
    .general.input.dim.tensor_w = 8,
    .general.input.dim.tensor_c = 16,
    .general.input.dim.num_elem = 1024,
    .general.input.stride.b = 4096,
    .general.input.stride.h = 512,
    .general.input.stride.w = 64,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 4352) /* Equivalent hex address = 0x342e1100UL */,
    .general.input.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 8,
    .general.output.dim.tensor_w = 8,
    .general.output.dim.tensor_c = 16,
    .general.output.dim.num_elem = 1024,
    .general.output.stride.b = 4096,
    .general.output.stride.h = 512,
    .general.output.stride.w = 64,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 4352) /* Equivalent hex address = 0x342e1100UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_RELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Relu_2 mapped on EmbedNets (FLOAT) as Relu | Category: Computational */
  ll_sw_forward_activ(&activ3_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 4352) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 8448) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 4352) /* Equivalent hex address = 0x342e1100UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 8448) /* Equivalent hex address = 0x342e2100UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=4    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_4(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=MaxPool node=MaxPool_3 */
  Pool_sw_info pool4_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 8,
    .general.input.dim.tensor_w = 8,
    .general.input.dim.tensor_c = 16,
    .general.input.dim.num_elem = 1024,
    .general.input.stride.b = 4096,
    .general.input.stride.h = 512,
    .general.input.stride.w = 64,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 4352) /* Equivalent hex address = 0x342e1100UL */,
    .general.input.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 4,
    .general.output.dim.tensor_w = 4,
    .general.output.dim.tensor_c = 16,
    .general.output.dim.num_elem = 256,
    .general.output.stride.b = 1024,
    .general.output.stride.h = 256,
    .general.output.stride.w = 64,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 2048) /* Equivalent hex address = 0x342e0800UL */,
    .general.output.format.is_signed = 0,
    /* Node-specific Hyper-parameters: */
    .pads = {0, 0, 0, 0},
    .strides = {2, 2},
    .k_shape = {2, 2},
    .general.type = LL_SW_MAXPOOL,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node MaxPool_3 mapped on EmbedNets (FLOAT) as MaxPool | Category: Computational */
  ll_sw_forward_pool(&pool4_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 2048) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 3072) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 2048) /* Equivalent hex address = 0x342e0800UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 3072) /* Equivalent hex address = 0x342e0c00UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=5    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_5(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Conv node=Conv2D_4 */
  Conv_sw_info conv5_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 4,
    .general.input.dim.tensor_w = 4,
    .general.input.dim.tensor_c = 16,
    .general.input.dim.num_elem = 256,
    .general.input.stride.b = 1024,
    .general.input.stride.h = 256,
    .general.input.stride.w = 64,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 2048) /* Equivalent hex address = 0x342e0800UL */,
    .general.input.format.is_signed = 0,
    /* "weights" tensor-related info: */
    .weights.dim.tensor_b = 32,
    .weights.dim.tensor_h = 3,
    .weights.dim.tensor_w = 3,
    .weights.dim.tensor_c = 16,
    .weights.dim.num_elem = 4608,
    .weights.stride.b = 576,
    .weights.stride.h = 192,
    .weights.stride.w = 64,
    .weights.stride.c = 4,
    .weights.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x70500000UL + 65536) /* Equivalent hex address = 0x70510000UL */,
    .weights.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 4,
    .general.output.dim.tensor_w = 4,
    .general.output.dim.tensor_c = 32,
    .general.output.dim.num_elem = 512,
    .general.output.stride.b = 2048,
    .general.output.stride.h = 512,
    .general.output.stride.w = 128,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 0,
    /* Node-specific Hyper-parameters: */
    .ngroup = 1,
    .pads = {1, 1, 1, 1},
    .strides = {1, 1},
    .dilations = {1, 1},
    .general.type = LL_SW_CONV,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Conv2D_4 mapped on EmbedNets (FLOAT) as Conv | Category: Computational */
  ll_sw_forward_conv(&conv5_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 2048) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 2048) /* Equivalent hex address = 0x342e0800UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=6    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_6(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Add node=Conv2D_4_addbias14 */
  Arith_sw_info arith6_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 4,
    .general.input.dim.tensor_w = 4,
    .general.input.dim.tensor_c = 32,
    .general.input.dim.num_elem = 512,
    .general.input.stride.b = 2048,
    .general.input.stride.h = 512,
    .general.input.stride.w = 128,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 32,
    .operand.dim.num_elem = 32,
    .operand.stride.b = 128,
    .operand.stride.h = 128,
    .operand.stride.w = 128,
    .operand.stride.c = 4,
    .operand.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x70500000UL + 87616) /* Equivalent hex address = 0x70515640UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 4,
    .general.output.dim.tensor_w = 4,
    .general.output.dim.tensor_c = 32,
    .general.output.dim.num_elem = 512,
    .general.output.stride.b = 2048,
    .general.output.stride.h = 512,
    .general.output.stride.w = 128,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 2048) /* Equivalent hex address = 0x342e0800UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_ARITHADD,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Conv2D_4_addbias14 mapped on EmbedNets (FLOAT) as Add | Category: Computational */
  ll_sw_forward_arith(&arith6_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 2048) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 4096) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 2048) /* Equivalent hex address = 0x342e0800UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 4096) /* Equivalent hex address = 0x342e1000UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=7    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_7(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Relu node=Relu_5 */
  Activ_sw_info activ7_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 4,
    .general.input.dim.tensor_w = 4,
    .general.input.dim.tensor_c = 32,
    .general.input.dim.num_elem = 512,
    .general.input.stride.b = 2048,
    .general.input.stride.h = 512,
    .general.input.stride.w = 128,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 2048) /* Equivalent hex address = 0x342e0800UL */,
    .general.input.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 4,
    .general.output.dim.tensor_w = 4,
    .general.output.dim.tensor_c = 32,
    .general.output.dim.num_elem = 512,
    .general.output.stride.b = 2048,
    .general.output.stride.h = 512,
    .general.output.stride.w = 128,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 2048) /* Equivalent hex address = 0x342e0800UL */,
    .general.output.format.is_signed = 0,
    .general.type = LL_SW_RELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Relu_5 mapped on EmbedNets (FLOAT) as Relu | Category: Computational */
  ll_sw_forward_activ(&activ7_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 2048) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 4096) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 2048) /* Equivalent hex address = 0x342e0800UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 4096) /* Equivalent hex address = 0x342e1000UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=8    nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_8(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=MaxPool node=MaxPool_6 */
  Pool_sw_info pool8_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 4,
    .general.input.dim.tensor_w = 4,
    .general.input.dim.tensor_c = 32,
    .general.input.dim.num_elem = 512,
    .general.input.stride.b = 2048,
    .general.input.stride.h = 512,
    .general.input.stride.w = 128,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 2048) /* Equivalent hex address = 0x342e0800UL */,
    .general.input.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 2,
    .general.output.dim.tensor_w = 2,
    .general.output.dim.tensor_c = 32,
    .general.output.dim.num_elem = 128,
    .general.output.stride.b = 512,
    .general.output.stride.h = 256,
    .general.output.stride.w = 128,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    /* Node-specific Hyper-parameters: */
    .pads = {0, 0, 0, 0},
    .strides = {2, 2},
    .k_shape = {2, 2},
    .general.type = LL_SW_MAXPOOL,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node MaxPool_6 mapped on EmbedNets (FLOAT) as MaxPool | Category: Computational */
  ll_sw_forward_pool(&pool8_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) /* Equivalent hex address = 0x342e0200UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=9    nodes=1   ------------------------------------------------------------------- */
/* no resources allocated to kind=Reshape node=Gemm_8_reshape_x_2 */

static void LL_ATON_Start_EpochBlock_9(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  /* Unit= 28 [NULL_UNIT 0] */
  /* kind=Reshape node=Gemm_8_reshape_x_2 */
  /* node=Gemm_8_reshape_x_2 satisfies input and output adjacency (DMA->DMA) and can be omitted */

  /* Dma inputs units to cycle: */
  /* Unit= 1 [STREAM_ENG_V2 1] */
  /* Emit conf for STREAM_ENG_V2 node=Gemm_8_reshape_x_2 input ports=0 range=1[0,512] */

  static const LL_Streng_TensorInitTypeDef Gemm_8_reshape_x_2_dma_init_in_0_9 = {
    /* memory canonical to batch=1 */
    .dir = 0,
    .noblk = 0,
    .align_right = 0,
    .nbits_unsigned = 0,
    .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */}, /* Gemm_8_transp_x_0 */
    .offset_start = 0,
    .offset_limit = 576,
    .frame_count = 0,
    .fwidth = 2,
    .fheight = 2,
    .batch_depth = 2,
    .batch_offset = 128,
    .frame_offset = 4,
    .line_offset = 0,
    .loop_offset = 512,
    .frame_loop_cnt = 32,
    .frame_tot_cnt = 32,
    .nbits_in = 16,
    .nbits_out = 16,
  };

  /* Unit=STREAM_ENG_V2 */
  LL_Streng_TensorInit(1, &Gemm_8_reshape_x_2_dma_init_in_0_9, 1);


  /* Dma input bandwidth from memory pools: */
  /* npuRAM5 -> 512 */

  /* Dma output units from cycle: */
  /* Unit= 8 [STREAM_ENG_V2 8] */
  /* Emit conf for STREAM_ENG_V2 node=Gemm_8_reshape_x_2 output ports=0 range=1[512,1024] */

  static const LL_Streng_TensorInitTypeDef Gemm_8_reshape_x_2_dma_init_out_0_9 = {
    /* to memory with batch=1 */
    .dir = 1,
    .raw = 1,
    .noblk = 0,
    .align_right = 0,
    .nbits_unsigned = 0,
    .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */}, /* Gemm_8_reshape_x_2 */
    .offset_start = 512,
    .offset_end = 516,
    .offset_limit = 1088,
    .frame_count = 0,
    .fwidth = 0,
    .fheight = 0,
    .batch_depth = 0,
    .batch_offset = 0,
    .frame_offset = 4,
    .line_offset = 0,
    .loop_offset = 0,
    .frame_loop_cnt = 0,
    .frame_tot_cnt = 128,
    .nbits_in = 16,
    .nbits_out = 16,
  };

  /* Unit=STREAM_ENG_V2 */
  LL_Streng_TensorInit(8, &Gemm_8_reshape_x_2_dma_init_out_0_9, 1);


  /* Dma output bandwidth to memory pools: */
  /* npuRAM5 <- 512 */

  static const LL_Switch_InitTypeDef switch_init_in_9[] = {
    { LL_Switch_Init_Dest() = ATONN_DSTPORT(STRSWITCH, 0, STRENG, 8, 0), LL_Switch_Init_Source(0) = ATONN_SRCPORT(STRSWITCH, 0, STRENG, 1, 0), LL_Switch_Init_Context(0) = 1, LL_Switch_Init_Frames(0) = 0, }, /* Gemm_8_reshape_x_2 OUT: in unit=STREAM_ENG_V2 8 in port=0 out unit=STREAM_ENG_V2 1 out port=0 */
  };


  /* epoch=9 */
  LL_Switch_Init(switch_init_in_9, 1);

  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache invalidate (only) operation (HW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 1024) */
  mcu_cache_invalidate_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) /* Equivalent hex address = 0x342e0200UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 1024) /* Equivalent hex address = 0x342e0400UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

  static LL_ATON_EnableUnits_InitTypeDef Enable_epoch_9_all_units[] = {
    { {STRENG, 8} }, /* STREAM_ENG_V2 */
    { {STRENG, 1} }, /* STREAM_ENG_V2 */
  };


  LL_ATON_EnableUnits_Init(Enable_epoch_9_all_units, 2);

}

static void LL_ATON_End_EpochBlock_9(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);

  static const LL_Switch_DeinitTypeDef switch_deinit_in_9[] = {
    { LL_Switch_Init_Dest() = ATONN_DSTPORT(STRSWITCH, 0, STRENG, 8, 0), LL_Switch_Init_Source(0) = ATONN_SRCPORT(STRSWITCH, 0, STRENG, 1, 0), LL_Switch_Init_Context(0) = 1, LL_Switch_Init_Frames(0) = 0, }, /* Gemm_8_reshape_x_2 OUT: in unit=STREAM_ENG_V2 8 in port=0 out unit=STREAM_ENG_V2 1 out port=0 */
  };


  /* epoch=9 */
  LL_Switch_Deinit(switch_deinit_in_9, 1);

  static LL_ATON_DisableUnits_InitTypeDef Disable_epoch_9_all_units[] = {
    { {STRENG, 8} }, /* STREAM_ENG_V2 */
    { {STRENG, 1} }, /* STREAM_ENG_V2 */
  };


  LL_ATON_DisableUnits_Init(Disable_epoch_9_all_units, 2);

}


/* scheduling epoch=10   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_10(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Conv node=Gemm_8_conv_4 */
  Conv_sw_info conv9_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 128,
    .general.input.stride.b = 512,
    .general.input.stride.h = 512,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) /* Equivalent hex address = 0x342e0200UL */,
    .general.input.format.is_signed = 0,
    /* "weights" tensor-related info: */
    .weights.dim.tensor_b = 128,
    .weights.dim.tensor_h = 1,
    .weights.dim.tensor_w = 1,
    .weights.dim.tensor_c = 128,
    .weights.dim.num_elem = 16384,
    .weights.stride.b = 512,
    .weights.stride.h = 512,
    .weights.stride.w = 512,
    .weights.stride.c = 4,
    .weights.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x70500000UL + 0) /* Equivalent hex address = 0x70500000UL */,
    .weights.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 128,
    .general.output.stride.b = 512,
    .general.output.stride.h = 512,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 1024) /* Equivalent hex address = 0x342e0400UL */,
    .general.output.format.is_signed = 0,
    /* Node-specific Hyper-parameters: */
    .ngroup = 1,
    .pads = {0, 0, 0, 0},
    .strides = {1, 1},
    .dilations = {1, 1},
    .general.type = LL_SW_CONV,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Gemm_8_conv_4 mapped on EmbedNets (FLOAT) as Conv | Category: Computational */
  ll_sw_forward_conv(&conv9_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 1024) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 1536) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 1024) /* Equivalent hex address = 0x342e0400UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 1536) /* Equivalent hex address = 0x342e0600UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=11   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_11(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Add node=Gemm_8_conv_4_addbias16 */
  Arith_sw_info arith10_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 128,
    .general.input.stride.b = 512,
    .general.input.stride.h = 512,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 1024) /* Equivalent hex address = 0x342e0400UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 128,
    .operand.dim.num_elem = 128,
    .operand.stride.b = 512,
    .operand.stride.h = 512,
    .operand.stride.w = 512,
    .operand.stride.c = 4,
    .operand.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x70500000UL + 87104) /* Equivalent hex address = 0x70515440UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 128,
    .general.output.stride.b = 512,
    .general.output.stride.h = 512,
    .general.output.stride.w = 512,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_ARITHADD,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Gemm_8_conv_4_addbias16 mapped on EmbedNets (FLOAT) as Add | Category: Computational */
  ll_sw_forward_arith(&arith10_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) /* Equivalent hex address = 0x342e0200UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=12   nodes=1   ------------------------------------------------------------------- */

/* scheduling epoch=13   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_13(const void *epoch_block)
{
  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Relu node=Relu_9 */
  Activ_sw_info activ11_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 128,
    .general.input.stride.b = 512,
    .general.input.stride.h = 512,
    .general.input.stride.w = 4,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 128,
    .general.output.dim.num_elem = 128,
    .general.output.stride.b = 512,
    .general.output.stride.h = 512,
    .general.output.stride.w = 4,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_RELU,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Relu_9 mapped on EmbedNets (FLOAT) as Relu | Category: Computational */
  ll_sw_forward_activ(&activ11_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) /* Equivalent hex address = 0x342e0200UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=14   nodes=1   ------------------------------------------------------------------- */

/* scheduling epoch=15   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_15(const void *epoch_block)
{
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache invalidate (only) operation for unaligned buffer start or end address (only line) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 544) */
  mcu_cache_invalidate_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) /* Equivalent hex address = 0x342e0200UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 544) /* Equivalent hex address = 0x342e0220UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Conv node=Gemm_10_conv_10 */
  Conv_sw_info conv12_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 128,
    .general.input.dim.num_elem = 128,
    .general.input.stride.b = 512,
    .general.input.stride.h = 512,
    .general.input.stride.w = 512,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.input.format.is_signed = 0,
    /* "weights" tensor-related info: */
    .weights.dim.tensor_b = 5,
    .weights.dim.tensor_h = 1,
    .weights.dim.tensor_w = 1,
    .weights.dim.tensor_c = 128,
    .weights.dim.num_elem = 640,
    .weights.stride.b = 512,
    .weights.stride.h = 512,
    .weights.stride.w = 512,
    .weights.stride.c = 4,
    .weights.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x70500000UL + 83968) /* Equivalent hex address = 0x70514800UL */,
    .weights.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 5,
    .general.output.dim.num_elem = 5,
    .general.output.stride.b = 20,
    .general.output.stride.h = 20,
    .general.output.stride.w = 20,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) /* Equivalent hex address = 0x342e0200UL */,
    .general.output.format.is_signed = 0,
    /* Node-specific Hyper-parameters: */
    .ngroup = 1,
    .pads = {0, 0, 0, 0},
    .strides = {1, 1},
    .dilations = {1, 1},
    .general.type = LL_SW_CONV,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Gemm_10_conv_10 mapped on EmbedNets (FLOAT) as Conv | Category: Computational */
  ll_sw_forward_conv(&conv12_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 544) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) /* Equivalent hex address = 0x342e0200UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 544) /* Equivalent hex address = 0x342e0220UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=16   nodes=1   ------------------------------------------------------------------- */

static void LL_ATON_End_EpochBlock_16(const void *epoch_block)
{
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache invalidate (only) operation for unaligned buffer start or end address (only line) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 32) */
  mcu_cache_invalidate_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 32) /* Equivalent hex address = 0x342e0020UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

  LL_ATON_LIB_UNUSED(epoch_block);


/* Unit= 27 [PROCESSOR 0] */
/* kind=Add node=Gemm_10_conv_10_addbias18 */
  Arith_sw_info arith13_sw_info = {
    /* "general.input" tensor-related info: */
    .general.input.dim.tensor_b = 1,
    .general.input.dim.tensor_h = 1,
    .general.input.dim.tensor_w = 1,
    .general.input.dim.tensor_c = 5,
    .general.input.dim.num_elem = 5,
    .general.input.stride.b = 20,
    .general.input.stride.h = 20,
    .general.input.stride.w = 20,
    .general.input.stride.c = 4,
    .general.input.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 512) /* Equivalent hex address = 0x342e0200UL */,
    .general.input.format.is_signed = 0,
    /* "operand" tensor-related info: */
    .operand.dim.tensor_b = 1,
    .operand.dim.tensor_h = 1,
    .operand.dim.tensor_w = 1,
    .operand.dim.tensor_c = 5,
    .operand.dim.num_elem = 5,
    .operand.stride.b = 20,
    .operand.stride.h = 20,
    .operand.stride.w = 20,
    .operand.stride.c = 4,
    .operand.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x70500000UL + 87808) /* Equivalent hex address = 0x70515700UL */,
    .operand.format.is_signed = 0,
    /* "general.output" tensor-related info: */
    .general.output.dim.tensor_b = 1,
    .general.output.dim.tensor_h = 1,
    .general.output.dim.tensor_w = 1,
    .general.output.dim.tensor_c = 5,
    .general.output.dim.num_elem = 5,
    .general.output.stride.b = 20,
    .general.output.stride.h = 20,
    .general.output.stride.w = 20,
    .general.output.stride.c = 4,
    .general.output.mem.start_offset = (unsigned char *)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */,
    .general.output.format.is_signed = 1,
    .general.type = LL_SW_ARITHADD,
  };

  /* Low Level SW Layer function invocation. This will exploit EmbedNets libs) */
  /* Node Gemm_10_conv_10_addbias18 mapped on EmbedNets (FLOAT) as Add | Category: Computational */
  ll_sw_forward_arith(&arith13_sw_info);
  // Lock MCU cache
  LL_ATON_LOCK_MCU_CACHE();

#if (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)
  /* *** MCU cache clean (only) operation (SW, whole range) *** */
  /*     memory pool: 1 */
  /*     start: (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) */
  /*     end:   (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 32) */
  mcu_cache_clean_range((uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 0) /* Equivalent hex address = 0x342e0000UL */, (uintptr_t)__LL_ATON_LIB_PHYSICAL_TO_VIRTUAL_ADDR(0x342e0000UL + 32) /* Equivalent hex address = 0x342e0020UL */);
#endif // (LL_ATON_PLATFORM == LL_ATON_PLAT_STM32N6)

  // Un-lock MCU cache
  LL_ATON_UNLOCK_MCU_CACHE();

}


/* scheduling epoch=17   nodes=1   ------------------------------------------------------------------- */

/* scheduling epoch=18   nodes=1   ------------------------------------------------------------------- */

/* scheduling DONE                 ------------------------------------------------------------------- */

const EpochBlock_ItemTypeDef *LL_ATON_EpochBlockItems_tof(void) {

  static const EpochBlock_ItemTypeDef ll_atonn_rt_epoch_block_array[] = {
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_1,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 1,
      .last_epoch_num = 1,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_2,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 2,
      .last_epoch_num = 2,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_3,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 3,
      .last_epoch_num = 3,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_4,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 4,
      .last_epoch_num = 4,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_5,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 5,
      .last_epoch_num = 5,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_6,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 6,
      .last_epoch_num = 6,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_7,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 7,
      .last_epoch_num = 7,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_8,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 8,
      .last_epoch_num = 8,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = LL_ATON_Start_EpochBlock_9,
      .end_epoch_block = LL_ATON_End_EpochBlock_9,
      .wait_mask = 0x00000100,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_hw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 9,
      .last_epoch_num = 9,
      .in_streng_mask = 0x00000002,
      .out_streng_mask = 0x00000100,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_10,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 10,
      .last_epoch_num = 10,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_11,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 11,
      .last_epoch_num = 11,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_13,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 13,
      .last_epoch_num = 13,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_15,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 15,
      .last_epoch_num = 15,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .start_epoch_block = NULL,
      .end_epoch_block = LL_ATON_End_EpochBlock_16,
      .wait_mask = 0x00000000,
      .flags = EpochBlock_Flags_epoch_start | EpochBlock_Flags_epoch_end | EpochBlock_Flags_pure_sw,
#ifdef LL_ATON_EB_DBG_INFO
      .epoch_num = 16,
      .last_epoch_num = 16,
      .in_streng_mask = 0x00000000,
      .out_streng_mask = 0x00000000,
      .estimated_npu_cycles = 0,
      .estimated_tot_cycles = 0,
#endif // LL_ATON_EB_DBG_INFO
    },
    {
      .flags = EpochBlock_Flags_last_eb,
    },
  };


  return ll_atonn_rt_epoch_block_array;
}

const LL_Buffer_InfoTypeDef *LL_ATON_Input_Buffers_Info_tof(void)
{
  static const uint32_t buff_info__shape_1_1_8_8[] = { 1, 8, 8, 1 };
  static const uint32_t buff_info__mem_shape_F_1_1_8_8[] = { 1, 1, 8, 8 };
#if LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
  static const uint32_t buff_info__shape_16_1_3_3[] = { 16, 3, 3, 1 };
  static const uint32_t buff_info__mem_shape_F_16_1_3_3[] = { 16, 1, 3, 3 };
  static const uint32_t buff_info__shape_32_16_3_3[] = { 32, 3, 3, 16 };
  static const uint32_t buff_info__mem_shape_L_32_16_3_3[] = { 32, 3, 3, 16 };
  static const uint32_t buff_info__shape_128_128_1_1[] = { 128, 1, 1, 128 };
  static const uint32_t buff_info__mem_shape_F_128_128_1_1[] = { 128, 128, 1, 1 };
  static const uint32_t buff_info__shape_5_128_1_1[] = { 5, 1, 1, 128 };
  static const uint32_t buff_info__mem_shape_F_5_128_1_1[] = { 5, 128, 1, 1 };
  static const uint32_t buff_info__shape_16_1_1[] = { 1, 1, 1, 16 };
  static const uint32_t buff_info__mem_shape_F_16_1_1[] = { 16, 1, 1 };
  static const uint32_t buff_info__shape_32_1_1[] = { 1, 1, 1, 32 };
  static const uint32_t buff_info__mem_shape_F_32_1_1[] = { 32, 1, 1 };
  static const uint32_t buff_info__shape_128_1_1[] = { 1, 1, 1, 128 };
  static const uint32_t buff_info__mem_shape_F_128_1_1[] = { 128, 1, 1 };
  static const uint32_t buff_info__shape_5_1_1[] = { 1, 1, 1, 5 };
  static const uint32_t buff_info__mem_shape_F_5_1_1[] = { 5, 1, 1 };
#endif // LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
  static const LL_Buffer_InfoTypeDef buff_info[] = {
    {
      .name = "Input_0_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 256,
      .offset_limit = 320,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_1_1_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_1_8_8,
    },
#if LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
    {
      .name = "Conv2D_1_weights",
      .addr_base = {(unsigned char *)(0x70500000UL) /* Equivalent hex address = 0x70500000UL */},
      .offset_start = 86528,
      .offset_end = 87104,
      .offset_limit = 87168,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_F_16_1_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_16_1_3_3,
    },
    {
      .name = "Conv2D_4_weights",
      .addr_base = {(unsigned char *)(0x70500000UL) /* Equivalent hex address = 0x70500000UL */},
      .offset_start = 65536,
      .offset_end = 83968,
      .offset_limit = 84032,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_L_32_16_3_3,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_32_16_3_3,
    },
    {
      .name = "Gemm_8_weights_transposed_3",
      .addr_base = {(unsigned char *)(0x70500000UL) /* Equivalent hex address = 0x70500000UL */},
      .offset_start = 0,
      .offset_end = 65536,
      .offset_limit = 65600,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_F_128_128_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_128_128_1_1,
    },
    {
      .name = "Gemm_10_weights_transposed_9",
      .addr_base = {(unsigned char *)(0x70500000UL) /* Equivalent hex address = 0x70500000UL */},
      .offset_start = 83968,
      .offset_end = 86528,
      .offset_limit = 86592,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_F_5_128_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_5_128_1_1,
    },
    {
      .name = "Conv2D_1_bias_copy13",
      .addr_base = {(unsigned char *)(0x70500000UL) /* Equivalent hex address = 0x70500000UL */},
      .offset_start = 87744,
      .offset_end = 87808,
      .offset_limit = 87872,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_F_16_1_1,
      .mem_ndims = 3,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_16_1_1,
    },
    {
      .name = "Conv2D_4_bias_copy15",
      .addr_base = {(unsigned char *)(0x70500000UL) /* Equivalent hex address = 0x70500000UL */},
      .offset_start = 87616,
      .offset_end = 87744,
      .offset_limit = 87808,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_F_32_1_1,
      .mem_ndims = 3,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_32_1_1,
    },
    {
      .name = "Gemm_8_bias_copy17",
      .addr_base = {(unsigned char *)(0x70500000UL) /* Equivalent hex address = 0x70500000UL */},
      .offset_start = 87104,
      .offset_end = 87616,
      .offset_limit = 87680,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_F_128_1_1,
      .mem_ndims = 3,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_128_1_1,
    },
    {
      .name = "Gemm_10_bias_copy19",
      .addr_base = {(unsigned char *)(0x70500000UL) /* Equivalent hex address = 0x70500000UL */},
      .offset_start = 87808,
      .offset_end = 87828,
      .offset_limit = 87896,
      .is_user_allocated = 0,
      .is_param = 1,
      .epoch = 0,
      .batch = 5,
      .mem_shape = buff_info__mem_shape_F_5_1_1,
      .mem_ndims = 3,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_5_1_1,
    },
#endif // LL_ATON_DBG_BUFFER_INFO_EXCLUDED == 0
    {
      .name = NULL,
    }
  };

  return buff_info;
}

const LL_Buffer_InfoTypeDef *LL_ATON_Output_Buffers_Info_tof(void)
{
  static const uint32_t buff_info__shape_1_5[] = { 1, 1, 5, 1 };
  static const uint32_t buff_info__mem_shape_U_1_5[] = { 1, 5 };
  static const LL_Buffer_InfoTypeDef buff_info[] = {
    {
      .name = "Gemm_10_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 20,
      .offset_limit = 88,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 17,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1_5,
      .mem_ndims = 2,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_5,
    },
    {
      .name = NULL,
    }
  };

  return buff_info;
}

const LL_Buffer_InfoTypeDef *LL_ATON_Internal_Buffers_Info_tof(void)
{
  static const uint32_t buff_info__shape_1_16_8_8[] = { 1, 8, 8, 16 };
  static const uint32_t buff_info__mem_shape_L_1_16_8_8[] = { 1, 8, 8, 16 };
  static const uint32_t buff_info__shape_1_16_4_4[] = { 1, 4, 4, 16 };
  static const uint32_t buff_info__mem_shape_L_1_16_4_4[] = { 1, 4, 4, 16 };
  static const uint32_t buff_info__shape_1_32_4_4[] = { 1, 4, 4, 32 };
  static const uint32_t buff_info__mem_shape_L_1_32_4_4[] = { 1, 4, 4, 32 };
  static const uint32_t buff_info__shape_1_32_2_2[] = { 1, 2, 2, 32 };
  static const uint32_t buff_info__mem_shape_L_1_32_2_2[] = { 1, 2, 2, 32 };
  static const uint32_t buff_info__shape_1_128_1_1[] = { 1, 1, 1, 128 };
  static const uint32_t buff_info__mem_shape_F_1_128_1_1[] = { 1, 128, 1, 1 };
  static const uint32_t buff_info__shape_1_128[] = { 1, 1, 128, 1 };
  static const uint32_t buff_info__mem_shape_U_1_128[] = { 1, 128 };
  static const uint32_t buff_info__shape_1_5_1_1[] = { 1, 1, 1, 5 };
  static const uint32_t buff_info__mem_shape_F_1_5_1_1[] = { 1, 5, 1, 1 };
  static const LL_Buffer_InfoTypeDef buff_info[] = {
    {
      .name = "Conv2D_1_out_0_in",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 256,
      .offset_end = 4352,
      .offset_limit = 4416,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 1,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_L_1_16_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_16_8_8,
    },
    {
      .name = "Conv2D_1_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 4352,
      .offset_end = 8448,
      .offset_limit = 8512,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 2,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_L_1_16_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_16_8_8,
    },
    {
      .name = "Relu_2_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 4352,
      .offset_end = 8448,
      .offset_limit = 8512,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 3,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_L_1_16_8_8,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_16_8_8,
    },
    {
      .name = "MaxPool_3_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 2048,
      .offset_end = 3072,
      .offset_limit = 3136,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 4,
      .batch = 16,
      .mem_shape = buff_info__mem_shape_L_1_16_4_4,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_16_4_4,
    },
    {
      .name = "Conv2D_4_out_0_in",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 2048,
      .offset_limit = 2112,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 5,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_L_1_32_4_4,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_32_4_4,
    },
    {
      .name = "Conv2D_4_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 2048,
      .offset_end = 4096,
      .offset_limit = 4160,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 6,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_L_1_32_4_4,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_32_4_4,
    },
    {
      .name = "Relu_5_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 2048,
      .offset_end = 4096,
      .offset_limit = 4160,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 7,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_L_1_32_4_4,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_32_4_4,
    },
    {
      .name = "MaxPool_6_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 512,
      .offset_limit = 576,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 8,
      .batch = 32,
      .mem_shape = buff_info__mem_shape_L_1_32_2_2,
      .mem_ndims = 4,
      .chpos = CHPos_Last,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_32_2_2,
    },
    {
      .name = "Gemm_8_reshape_x_2",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 512,
      .offset_end = 1024,
      .offset_limit = 1088,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 9,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_F_1_128_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_1_1,
    },
    {
      .name = "Gemm_8_conv_4_in",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 1024,
      .offset_end = 1536,
      .offset_limit = 1600,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 10,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_F_1_128_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_1_1,
    },
    {
      .name = "Gemm_8_conv_4",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 512,
      .offset_limit = 576,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 11,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_F_1_128_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_1_1,
    },
    {
      .name = "Gemm_8_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 512,
      .offset_limit = 576,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 12,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1_128,
      .mem_ndims = 2,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128,
    },
    {
      .name = "Relu_9_out_0",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 512,
      .offset_limit = 576,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 13,
      .batch = 1,
      .mem_shape = buff_info__mem_shape_U_1_128,
      .mem_ndims = 2,
      .chpos = CHPos_UNDEFINED,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128,
    },
    {
      .name = "Gemm_10_reshape_x_8",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 512,
      .offset_limit = 576,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 14,
      .batch = 128,
      .mem_shape = buff_info__mem_shape_F_1_128_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 0,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_128_1_1,
    },
    {
      .name = "Gemm_10_conv_10_in",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 512,
      .offset_end = 532,
      .offset_limit = 600,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 15,
      .batch = 5,
      .mem_shape = buff_info__mem_shape_F_1_5_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_5_1_1,
    },
    {
      .name = "Gemm_10_conv_10",
      .addr_base = {(unsigned char *)(0x342e0000UL) /* Equivalent hex address = 0x342e0000UL */},
      .offset_start = 0,
      .offset_end = 20,
      .offset_limit = 88,
      .is_user_allocated = 0,
      .is_param = 0,
      .epoch = 16,
      .batch = 5,
      .mem_shape = buff_info__mem_shape_F_1_5_1_1,
      .mem_ndims = 4,
      .chpos = CHPos_First,
      .Qm = 0,
      .Qn = 0,
      .Qunsigned = 1,
      .type = DataType_FLOAT,
      .nbits = 32,
      .ndims = 4,
      .shape = buff_info__shape_1_5_1_1,
    },
    {
      .name = NULL,
    }
  };

  return buff_info;
}

